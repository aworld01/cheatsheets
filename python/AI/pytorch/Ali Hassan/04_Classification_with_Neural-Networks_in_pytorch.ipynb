{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f202c68-6a7e-45ce-8fbd-26c925f6c24f",
   "metadata": {},
   "source": [
    "<h1>1:00:00/1:23:15</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f45794-8bdf-4418-8b9a-d2c73e78402d",
   "metadata": {},
   "source": [
    "<h1>Workflow</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd49570-f7b3-4e5d-ada0-6c0d5b448056",
   "metadata": {},
   "source": [
    "<h2>\n",
    "    0. Import important libraries<br>\n",
    "    1. Get dataset ready (turn into tensor and batches)<br>\n",
    "    2. Build a NeuralNetwork model for classification<br>\n",
    "    3. Pick a loss function and optimizer<br>\n",
    "    4. Build a training loop<br>\n",
    "    5. Evaluate your model<br>\n",
    "    6. Improve your model<br>\n",
    "    7. Save the model\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987f0b7e-5270-427e-b150-0574d7344094",
   "metadata": {},
   "source": [
    "<h2>0. Import important libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b63d2a9c-904b-4020-a408-065b5198f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dec84e-5a64-4a1f-9d70-a7a41dfb934e",
   "metadata": {},
   "source": [
    "<h2>1. Get dataset ready (turn into tensor and batches)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd435765-2141-4d17-8b5c-7038c59efd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.FashionMNIST(root='/dataset',train=True,transform=transforms.ToTensor(),download=True)\n",
    "test_dataset = datasets.FashionMNIST(root='/dataset',train=False,transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1a7dd70-4be5-4566-b3c7-12a801fe60ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: /dataset\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset #to check dataset items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e51e47f-8209-4cbc-9914-b6f6d5edae11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: /dataset\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset #to check dataset items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "06bd1589-be7b-4194-8ef2-5b35f7cf6c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc83527e-3bb2-4e10-a207-fdd68be4c535",
   "metadata": {},
   "source": [
    "<h3>1.2 Conveting data into batches</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "719061ae-4852-4e2f-be74-32be1a952b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d20313e0-5275-4d52-a9d2-9361bee598fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938\n",
      "157\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader)) #60000 / 64 = 938\n",
    "print(len(test_loader)) #10000 / 64 = 157"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cb0069-010f-4e05-9ac5-61ea13fc1918",
   "metadata": {},
   "source": [
    "<h2>2. Build a Neural Network model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53db2484-bc27-4fdf-80e7-4f578e514523",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self,in_dim,n_hidden_1,n_hidden_2,out_dim):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(in_dim,n_hidden_1),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(n_hidden_1,n_hidden_2),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(n_hidden_2,out_dim),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        a = self.layer1(x)\n",
    "        b = self.layer2(a)\n",
    "        c = self.layer3(b)\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "338a444f-a89f-4add-831f-88443d01919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 28*28 #784\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "out_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "61c265ce-10ca-4130-8b92-348cd6df192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(in_dim,n_hidden_1,n_hidden_2,out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4edc4607-5a10-4b22-830a-92f7171239ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (layer1): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=10, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "317f5612-d6b4-4f70-af5e-882765ea81be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer1.0.weight',\n",
       "              tensor([[ 0.0199, -0.0118,  0.0318,  ...,  0.0037, -0.0020, -0.0247],\n",
       "                      [-0.0352, -0.0242, -0.0014,  ..., -0.0326, -0.0239, -0.0294],\n",
       "                      [ 0.0014, -0.0107,  0.0117,  ...,  0.0284, -0.0334, -0.0120],\n",
       "                      ...,\n",
       "                      [ 0.0282,  0.0144,  0.0339,  ...,  0.0158, -0.0274,  0.0315],\n",
       "                      [ 0.0342,  0.0111,  0.0122,  ..., -0.0326, -0.0202,  0.0274],\n",
       "                      [ 0.0001,  0.0172,  0.0092,  ...,  0.0207, -0.0071,  0.0106]])),\n",
       "             ('layer1.0.bias',\n",
       "              tensor([ 3.4237e-02, -4.7148e-03,  3.1770e-02, -9.2099e-04, -3.4861e-02,\n",
       "                      -3.2221e-02,  3.1155e-02,  1.1015e-02, -2.1837e-02, -2.8381e-02,\n",
       "                      -2.6451e-02, -2.8578e-02,  6.3222e-03, -1.8590e-02, -2.1644e-02,\n",
       "                       1.4677e-02,  2.3620e-02,  2.8055e-02,  1.3657e-02, -3.8357e-03,\n",
       "                       1.3007e-03,  3.0306e-02,  1.6828e-02,  5.4313e-03,  4.0592e-03,\n",
       "                       1.2658e-02, -3.0419e-02, -2.7991e-02, -8.1827e-03,  5.9628e-04,\n",
       "                       2.5107e-02, -3.0706e-02, -4.6718e-03, -3.5884e-03,  1.7519e-02,\n",
       "                      -1.0843e-02, -1.9573e-03,  2.9814e-02,  3.5356e-02,  3.3736e-02,\n",
       "                      -2.4059e-02, -1.2901e-02, -1.9636e-03, -3.0090e-02, -9.4029e-03,\n",
       "                       7.0302e-04,  9.7332e-03,  1.9188e-02, -2.1501e-02, -2.0035e-02,\n",
       "                      -2.3130e-02, -1.4271e-02,  1.1629e-02,  3.4981e-02,  1.1105e-05,\n",
       "                       3.1440e-02,  2.0351e-02, -5.5595e-03,  1.3973e-02, -1.1702e-02,\n",
       "                       1.1104e-03,  2.8868e-02, -7.1532e-03, -3.0212e-03,  5.9957e-03,\n",
       "                      -2.8799e-02,  2.9381e-02, -1.5220e-02,  2.8620e-02, -2.4890e-02,\n",
       "                      -4.6778e-03,  1.3650e-02,  3.0558e-02, -1.0028e-02, -1.5035e-02,\n",
       "                       3.3684e-02,  9.0885e-04,  2.7758e-02, -1.9838e-02,  8.1082e-03,\n",
       "                      -3.2622e-02,  2.9135e-02,  4.2835e-03, -3.3052e-02,  2.4007e-02,\n",
       "                       1.2780e-02,  2.4241e-02,  3.3981e-02,  2.8277e-02,  1.8068e-03,\n",
       "                       1.7726e-02, -5.5274e-03, -3.9668e-03, -1.9298e-02, -2.1093e-03,\n",
       "                       2.7458e-02,  3.5493e-02,  2.3989e-03, -2.5202e-02, -2.2434e-02,\n",
       "                      -3.4658e-02, -1.9825e-02, -2.6222e-02,  3.3252e-03,  1.3865e-02,\n",
       "                       6.6702e-03,  2.2112e-03, -1.7305e-02, -3.2016e-02,  2.9947e-02,\n",
       "                      -2.2350e-03,  3.2876e-02,  3.4869e-02,  6.2026e-03, -3.1997e-02,\n",
       "                      -1.7092e-02,  1.4278e-02, -2.9073e-02, -2.4667e-02,  9.6297e-03,\n",
       "                       1.8962e-02,  1.7699e-02, -1.9909e-02, -2.7871e-02,  2.2121e-03,\n",
       "                      -1.8961e-02, -2.3964e-02, -1.1174e-02,  1.2306e-02, -2.2326e-02,\n",
       "                       2.8034e-02,  2.6533e-02,  2.3810e-02, -5.3294e-03, -1.8964e-02,\n",
       "                      -1.1352e-02, -1.5272e-02, -9.8848e-04, -1.4447e-02,  1.6709e-02,\n",
       "                      -1.0092e-02, -1.5359e-02, -2.4402e-02,  2.8838e-02, -2.4938e-02,\n",
       "                      -2.7367e-02, -1.4070e-02, -3.4393e-02, -1.7152e-02, -2.9635e-02,\n",
       "                      -1.4841e-02, -2.9375e-03,  1.6804e-02,  1.2002e-02,  1.1237e-02,\n",
       "                      -1.6641e-03,  2.7300e-02,  9.1085e-03, -2.6073e-02, -7.9252e-03,\n",
       "                      -9.4416e-03, -7.7478e-04, -6.1481e-03, -2.3476e-03,  6.4565e-03,\n",
       "                      -2.3480e-02,  9.3039e-03, -2.4052e-02, -3.4796e-02, -2.6606e-02,\n",
       "                       1.8228e-03,  3.3120e-02, -1.3865e-02, -4.6369e-03, -1.4760e-02,\n",
       "                       2.5070e-02,  3.0641e-02, -1.0067e-02, -8.9310e-03, -3.1595e-02,\n",
       "                      -3.5886e-03,  1.3214e-02, -4.6688e-03, -1.4139e-02, -4.5065e-03,\n",
       "                      -1.6382e-02,  2.9162e-02, -1.8602e-02,  2.5401e-02, -2.2410e-02,\n",
       "                      -2.5126e-02,  2.8826e-02, -9.8846e-03,  2.6422e-02, -3.3460e-02,\n",
       "                      -1.3216e-02,  5.8835e-03, -1.9633e-03,  1.1830e-02,  2.1865e-02,\n",
       "                      -2.0227e-02, -2.4497e-02,  6.0187e-03, -1.5466e-02, -2.8134e-03,\n",
       "                       8.3565e-03, -3.3820e-02,  2.1166e-02, -6.2676e-03, -1.5256e-02,\n",
       "                      -1.5585e-02,  2.4136e-02, -1.8299e-02,  1.9737e-02, -9.6493e-03,\n",
       "                      -5.3379e-03,  3.3273e-02,  1.2021e-02, -2.7986e-02,  1.9388e-02,\n",
       "                      -1.6707e-02, -2.1408e-03, -4.0534e-03, -1.8210e-03,  1.3252e-02,\n",
       "                       1.2195e-02, -1.5734e-02, -7.4640e-04, -1.2216e-04, -1.9503e-02,\n",
       "                       1.8734e-02, -1.9418e-02, -1.8230e-02,  3.0622e-02,  1.7651e-02,\n",
       "                       2.1868e-02,  2.0996e-02,  3.3240e-02,  2.8897e-02, -1.5150e-02,\n",
       "                      -9.5796e-04, -1.1937e-02, -1.1340e-02, -3.1302e-02, -1.7968e-03,\n",
       "                       1.7123e-02,  3.4269e-02,  2.1249e-02, -1.7300e-02,  2.2856e-03,\n",
       "                      -7.9635e-03,  2.1242e-02,  2.6748e-02,  2.0275e-02, -2.9162e-02,\n",
       "                       3.3909e-02, -2.4063e-02,  9.6988e-03,  2.3212e-02, -3.2544e-02,\n",
       "                      -9.8913e-03, -1.0021e-02, -2.6282e-02,  3.3118e-02, -5.1165e-03,\n",
       "                      -2.2142e-02, -8.9474e-03,  1.5483e-02,  1.5587e-02, -8.1981e-03,\n",
       "                      -1.4107e-02, -1.7620e-02, -2.1292e-02, -2.4466e-02,  3.2711e-03,\n",
       "                      -1.5122e-02, -4.2406e-03, -2.3565e-02,  9.0579e-04,  1.8241e-02,\n",
       "                       1.5767e-02, -2.2379e-02,  4.7998e-03, -1.3831e-02, -6.3137e-03,\n",
       "                       3.5536e-02, -3.3749e-02, -1.6241e-03,  2.6464e-02, -1.2394e-02,\n",
       "                      -9.6646e-03, -1.2224e-02, -1.6463e-03,  1.3338e-02, -1.0410e-02,\n",
       "                      -2.4217e-02, -3.3221e-02,  2.8953e-02,  9.1634e-03,  1.3192e-02])),\n",
       "             ('layer2.0.weight',\n",
       "              tensor([[ 0.0135, -0.0011, -0.0395,  ...,  0.0450, -0.0021, -0.0050],\n",
       "                      [-0.0033, -0.0433,  0.0422,  ...,  0.0151, -0.0384,  0.0158],\n",
       "                      [ 0.0110,  0.0323,  0.0551,  ...,  0.0074,  0.0278,  0.0541],\n",
       "                      ...,\n",
       "                      [-0.0187,  0.0474,  0.0521,  ...,  0.0295, -0.0570,  0.0256],\n",
       "                      [-0.0230, -0.0398, -0.0462,  ...,  0.0313, -0.0112, -0.0394],\n",
       "                      [-0.0175,  0.0155, -0.0147,  ..., -0.0252, -0.0134,  0.0010]])),\n",
       "             ('layer2.0.bias',\n",
       "              tensor([ 1.7533e-02, -8.1032e-03, -3.3006e-02, -6.3975e-03,  4.8583e-02,\n",
       "                       3.3215e-02, -4.2804e-02, -4.7330e-02, -5.4564e-02,  6.4156e-04,\n",
       "                      -5.6783e-02, -2.1626e-02, -1.1655e-02,  4.8513e-02,  4.4748e-02,\n",
       "                      -4.3761e-02, -2.7058e-02,  2.4107e-02,  5.6627e-02, -9.1061e-03,\n",
       "                       4.5296e-02,  3.4872e-02,  4.7084e-03,  1.8732e-02,  5.0780e-03,\n",
       "                       4.2669e-02,  1.9875e-02,  9.2216e-03, -4.0660e-02, -3.1524e-02,\n",
       "                      -2.9119e-02,  1.4937e-02, -9.2632e-03, -1.1458e-03,  3.8486e-02,\n",
       "                       2.7125e-02, -4.0415e-02, -3.8010e-02,  2.0746e-02,  1.6726e-02,\n",
       "                      -5.1850e-02, -4.2677e-02, -3.5598e-02, -2.5352e-02, -9.2773e-04,\n",
       "                       4.3477e-02, -5.1271e-02,  8.4621e-03, -5.2944e-02, -5.0147e-02,\n",
       "                      -4.2027e-02, -2.6187e-02, -5.2593e-03,  1.7810e-02,  2.8490e-02,\n",
       "                       4.4282e-02,  5.0382e-02, -2.6783e-02,  3.3463e-03,  5.3045e-02,\n",
       "                      -1.5653e-02,  9.0644e-03, -5.3303e-02, -1.1645e-03,  3.3643e-02,\n",
       "                      -2.2795e-02,  4.1203e-02,  2.8881e-02, -3.7594e-02,  8.4326e-05,\n",
       "                      -1.7247e-02, -5.4574e-02,  3.4785e-02, -1.3601e-02,  5.3099e-02,\n",
       "                      -4.3645e-03,  4.2674e-02,  6.4707e-03,  4.1197e-02,  5.6007e-02,\n",
       "                       3.2621e-02, -3.9676e-02,  2.1854e-02, -3.4371e-02,  3.1295e-02,\n",
       "                      -1.0289e-02,  4.2026e-02, -1.3481e-02,  4.5796e-02,  5.4880e-02,\n",
       "                       2.0311e-02,  7.2563e-03,  2.8264e-02,  2.6922e-02,  1.5570e-02,\n",
       "                       4.1421e-02,  3.6432e-02,  4.3154e-02, -1.2321e-02,  5.6302e-02])),\n",
       "             ('layer3.0.weight',\n",
       "              tensor([[-0.0383, -0.0414,  0.0546, -0.0862,  0.0127,  0.0116, -0.0097, -0.0977,\n",
       "                       -0.0466, -0.0439, -0.0537,  0.0591,  0.0595, -0.0446, -0.0358, -0.0933,\n",
       "                        0.0470, -0.0505, -0.0733, -0.0300,  0.0593, -0.0486, -0.0238,  0.0430,\n",
       "                        0.0469,  0.0879,  0.0079, -0.0604, -0.0314, -0.0428, -0.0532, -0.0613,\n",
       "                       -0.0698,  0.0790, -0.0803,  0.0825, -0.0313, -0.0101, -0.0455, -0.0839,\n",
       "                       -0.0936,  0.0334, -0.0925,  0.0931, -0.0376, -0.0357,  0.0230,  0.0219,\n",
       "                        0.0285,  0.0179,  0.0069, -0.0581,  0.0949, -0.0121, -0.0333,  0.0347,\n",
       "                        0.0931, -0.0711, -0.0112,  0.0797, -0.0088, -0.0753, -0.0727, -0.0231,\n",
       "                       -0.0395, -0.0138,  0.0120, -0.0335,  0.0068, -0.0231, -0.0946,  0.0267,\n",
       "                       -0.0200,  0.0259,  0.0770, -0.0236, -0.0253,  0.0066, -0.0575, -0.0261,\n",
       "                       -0.0054,  0.0674,  0.0315,  0.0209,  0.0315, -0.0731, -0.0544, -0.0807,\n",
       "                        0.0971,  0.0076,  0.0136, -0.0027, -0.0358,  0.0353, -0.0329,  0.0881,\n",
       "                        0.0104, -0.0887, -0.0429, -0.0158],\n",
       "                      [-0.0141,  0.0203, -0.0759, -0.0855,  0.0612,  0.0139, -0.0611,  0.0380,\n",
       "                       -0.0497,  0.0662,  0.0279, -0.0422,  0.0877,  0.0526, -0.0625,  0.0574,\n",
       "                       -0.0036, -0.0527,  0.0197, -0.0781, -0.0479,  0.0437, -0.0784,  0.0961,\n",
       "                        0.0771, -0.0186,  0.0712, -0.0850, -0.0717,  0.0399, -0.0351,  0.0081,\n",
       "                        0.0304, -0.0215,  0.0334,  0.0164, -0.0560, -0.0382, -0.0228,  0.0351,\n",
       "                        0.0453,  0.0905, -0.0078,  0.0397,  0.0913,  0.0795,  0.0185,  0.0287,\n",
       "                       -0.0181,  0.0410,  0.0272,  0.0250, -0.0376,  0.0290,  0.0309, -0.0880,\n",
       "                       -0.0450,  0.0078, -0.0694,  0.0768, -0.0652, -0.0957, -0.0503,  0.0674,\n",
       "                        0.0601,  0.0070,  0.0967,  0.0977, -0.0735, -0.0601,  0.0929, -0.0761,\n",
       "                        0.0875,  0.0088,  0.0975,  0.0941,  0.0127, -0.0240,  0.0066, -0.0253,\n",
       "                       -0.0088, -0.0113, -0.0567, -0.0120,  0.0727,  0.0339, -0.0582, -0.0245,\n",
       "                       -0.0356,  0.0174, -0.0962,  0.0132, -0.0235, -0.0737,  0.0195,  0.0444,\n",
       "                        0.0073,  0.0397,  0.0338, -0.0099],\n",
       "                      [ 0.0232,  0.0978, -0.0436,  0.0628,  0.0773,  0.0353,  0.0715,  0.0179,\n",
       "                        0.0945, -0.0313,  0.0348,  0.0573,  0.0894, -0.0702, -0.0923,  0.0198,\n",
       "                       -0.0298,  0.0046, -0.0525,  0.0296, -0.0566, -0.0557, -0.0505, -0.0112,\n",
       "                        0.0136, -0.0586,  0.0914,  0.0337, -0.0789,  0.0310,  0.0456,  0.0330,\n",
       "                        0.0812, -0.0391,  0.0480,  0.0676, -0.0151,  0.0559, -0.0119, -0.0796,\n",
       "                       -0.0980, -0.0330,  0.0931,  0.0861,  0.0850,  0.0805,  0.0368, -0.0777,\n",
       "                        0.0397,  0.0313, -0.0427, -0.0502,  0.0867, -0.0109,  0.0139,  0.0760,\n",
       "                        0.0866, -0.0010, -0.0738,  0.0482, -0.0594,  0.0913,  0.0248,  0.0440,\n",
       "                        0.0147, -0.0854,  0.0254, -0.0536, -0.0162,  0.0897,  0.0993, -0.0618,\n",
       "                        0.0866,  0.0908,  0.0961, -0.0015,  0.0847,  0.0231,  0.0576, -0.0277,\n",
       "                       -0.0313,  0.0825, -0.0597,  0.0839,  0.0952, -0.0085,  0.0328,  0.0084,\n",
       "                        0.0047, -0.0511, -0.0170,  0.0281, -0.0711, -0.0272,  0.0311, -0.0390,\n",
       "                        0.0622, -0.0702,  0.0149, -0.0385],\n",
       "                      [-0.0566, -0.0492, -0.0483, -0.0553,  0.0054, -0.0181, -0.0666,  0.0691,\n",
       "                        0.0297, -0.0550,  0.0666, -0.0406,  0.0439,  0.0925,  0.0357,  0.0077,\n",
       "                        0.0166, -0.0802,  0.0210,  0.0693, -0.0330,  0.0684, -0.0247, -0.0172,\n",
       "                        0.0994,  0.0877, -0.0168,  0.0837, -0.0770, -0.0944, -0.0754, -0.0857,\n",
       "                       -0.0379, -0.0784, -0.0729,  0.0720,  0.0341,  0.0396, -0.0074,  0.0570,\n",
       "                       -0.0283,  0.0965, -0.0858, -0.0364, -0.0160,  0.0979,  0.0360, -0.0172,\n",
       "                       -0.0159, -0.0756, -0.0493,  0.0505,  0.0662, -0.0318,  0.0075,  0.0012,\n",
       "                        0.0758,  0.0292,  0.0701, -0.0741, -0.0314,  0.0408, -0.0524, -0.0296,\n",
       "                        0.0222, -0.0659,  0.0295, -0.0257, -0.0906, -0.0462,  0.0478,  0.0626,\n",
       "                        0.0519,  0.0310,  0.0832,  0.0631, -0.0766,  0.0787,  0.0394,  0.0690,\n",
       "                        0.0926,  0.0172, -0.0140, -0.0919,  0.0823,  0.0249,  0.0564, -0.0920,\n",
       "                        0.0189, -0.0485, -0.0433, -0.0989, -0.0483, -0.0756,  0.0100,  0.0375,\n",
       "                        0.0376, -0.0802,  0.0022,  0.0809],\n",
       "                      [-0.0607,  0.0799,  0.0853,  0.0648,  0.0892,  0.0712, -0.0161,  0.0460,\n",
       "                       -0.0577,  0.0373, -0.0744,  0.0465, -0.0116, -0.0635, -0.0828,  0.0945,\n",
       "                        0.0731,  0.0866,  0.0806,  0.0228,  0.0351, -0.0432,  0.0455,  0.0012,\n",
       "                       -0.0280,  0.0482,  0.0594,  0.0624, -0.0981,  0.0776,  0.0079,  0.0130,\n",
       "                       -0.0379, -0.0856, -0.0743, -0.0176, -0.0737,  0.0078,  0.0741,  0.0132,\n",
       "                       -0.0566,  0.0427, -0.0872,  0.0674, -0.0183, -0.0697,  0.0952, -0.0575,\n",
       "                        0.0514, -0.0971,  0.0193,  0.0236, -0.0449, -0.0446,  0.0268,  0.0553,\n",
       "                        0.0421,  0.0309,  0.0158,  0.0529,  0.0038, -0.0930,  0.0111, -0.0234,\n",
       "                       -0.0315, -0.0554,  0.0064, -0.0298,  0.0836,  0.0064,  0.0402, -0.0558,\n",
       "                       -0.0733, -0.0937, -0.0257,  0.0878,  0.0668,  0.0944,  0.0068, -0.0673,\n",
       "                       -0.0298,  0.0715,  0.0809, -0.0377, -0.0946,  0.0533, -0.0960, -0.0229,\n",
       "                       -0.0948,  0.0071,  0.0320, -0.0754, -0.0086, -0.0556,  0.0820, -0.0533,\n",
       "                       -0.0550, -0.0882,  0.0896,  0.0894],\n",
       "                      [ 0.0422,  0.0380,  0.0797,  0.0533,  0.0737,  0.0953, -0.0404,  0.0295,\n",
       "                       -0.0112,  0.0446,  0.0565, -0.0447,  0.0698, -0.0549, -0.0271, -0.0581,\n",
       "                        0.0470, -0.0306, -0.0470,  0.0360, -0.0268,  0.0932, -0.0963, -0.0879,\n",
       "                       -0.0613,  0.0258, -0.0268,  0.0783, -0.0263,  0.0189, -0.0842,  0.0223,\n",
       "                       -0.0104, -0.0384, -0.0314, -0.0938,  0.0239, -0.0769,  0.0642,  0.0266,\n",
       "                       -0.0439, -0.0323,  0.0397, -0.0865,  0.0459,  0.0474, -0.0015, -0.0007,\n",
       "                       -0.0629, -0.0337, -0.0591, -0.0350,  0.0200, -0.0655, -0.0483, -0.0952,\n",
       "                       -0.0216, -0.0894,  0.0035, -0.0828, -0.0540, -0.0862, -0.0015, -0.0746,\n",
       "                        0.0778,  0.0326, -0.0999, -0.0229,  0.0907,  0.0238,  0.0638,  0.0842,\n",
       "                       -0.0299, -0.0324,  0.0960,  0.0751, -0.0567, -0.0459,  0.0111, -0.0606,\n",
       "                       -0.0659,  0.0283,  0.0398,  0.0386, -0.0463,  0.0142,  0.0606, -0.0186,\n",
       "                       -0.0411, -0.0390, -0.0061, -0.0312, -0.0135, -0.0798, -0.0460,  0.0406,\n",
       "                        0.0128,  0.0519, -0.0354,  0.0375],\n",
       "                      [ 0.0420, -0.0477,  0.0958, -0.0188, -0.0276, -0.0659, -0.0136,  0.0265,\n",
       "                        0.0518,  0.0789, -0.0759,  0.0887, -0.0359,  0.0607, -0.0771, -0.0630,\n",
       "                        0.0089, -0.0007,  0.0156,  0.0306, -0.0149, -0.0436,  0.0673,  0.0605,\n",
       "                        0.0248, -0.0618,  0.0678,  0.0421,  0.0417,  0.0863, -0.0457, -0.0204,\n",
       "                        0.0062, -0.0116, -0.0425, -0.0051, -0.0029, -0.0186, -0.0657,  0.0145,\n",
       "                       -0.0514, -0.0593, -0.0427, -0.0638, -0.0366,  0.0996,  0.0204,  0.0965,\n",
       "                       -0.0340,  0.0921, -0.0133, -0.0451, -0.0910,  0.0788,  0.0363, -0.0226,\n",
       "                        0.0497, -0.0603,  0.0665,  0.0269, -0.0770, -0.0761,  0.0757,  0.0363,\n",
       "                        0.0623,  0.0282,  0.0673, -0.0955,  0.0912,  0.0314, -0.0097, -0.0687,\n",
       "                        0.0034, -0.0780, -0.0751, -0.0122, -0.0622, -0.0089,  0.0328, -0.0499,\n",
       "                        0.0794,  0.0144, -0.0702,  0.0663,  0.0484,  0.0045,  0.0647,  0.0627,\n",
       "                        0.0607,  0.0752, -0.0440, -0.0255, -0.0805,  0.0617,  0.0276,  0.0794,\n",
       "                       -0.0625,  0.0244, -0.0394, -0.0679],\n",
       "                      [-0.0366, -0.0500, -0.0039, -0.0795,  0.0161,  0.0581,  0.0685, -0.0297,\n",
       "                       -0.0893, -0.0373, -0.0764,  0.0104,  0.0077, -0.0817, -0.0172, -0.0251,\n",
       "                       -0.0059,  0.0390,  0.0688,  0.0498, -0.0209,  0.0086, -0.0694,  0.0479,\n",
       "                        0.0135, -0.0724,  0.0705, -0.0192, -0.0429,  0.0179,  0.0504,  0.0280,\n",
       "                        0.0675,  0.0511,  0.0539, -0.0568,  0.0508,  0.0984,  0.0807,  0.0267,\n",
       "                        0.0669,  0.0798,  0.0019, -0.0012,  0.0833, -0.0432,  0.0235,  0.0252,\n",
       "                       -0.0129,  0.0268,  0.0066,  0.0743,  0.0828, -0.0757,  0.0885,  0.0617,\n",
       "                       -0.0574,  0.0885,  0.0822,  0.0395, -0.0983, -0.0257,  0.0837,  0.0846,\n",
       "                       -0.0006, -0.0149,  0.0159,  0.0124, -0.0062, -0.0778, -0.0247,  0.0280,\n",
       "                       -0.0462, -0.0600, -0.0700, -0.0773,  0.0359,  0.0214,  0.0461, -0.0649,\n",
       "                        0.0484,  0.0379,  0.0271,  0.0622, -0.0111,  0.0607,  0.0813,  0.0173,\n",
       "                        0.0360,  0.0467,  0.0493, -0.0258, -0.0638,  0.0487, -0.0780,  0.0361,\n",
       "                       -0.0107,  0.0930, -0.0675, -0.0641],\n",
       "                      [ 0.0430,  0.0411,  0.0910,  0.0359,  0.0218,  0.0436,  0.0952,  0.0506,\n",
       "                       -0.0320, -0.0523,  0.0428, -0.0866,  0.0202, -0.0899, -0.0772,  0.0959,\n",
       "                       -0.0901, -0.0819,  0.0005,  0.0833, -0.0275,  0.0528,  0.0211, -0.0199,\n",
       "                       -0.0573, -0.0939,  0.0305, -0.0624,  0.0800,  0.0675, -0.0492,  0.0327,\n",
       "                        0.0785,  0.0542, -0.0386,  0.0205, -0.0579, -0.0082, -0.0017,  0.0848,\n",
       "                       -0.0545, -0.0398, -0.0084, -0.0350,  0.0327,  0.0268, -0.0774,  0.0100,\n",
       "                        0.0429,  0.0672,  0.0930, -0.0221, -0.0399, -0.0814, -0.0296,  0.0293,\n",
       "                       -0.0640, -0.0544,  0.0231,  0.0518, -0.0229, -0.0337, -0.0407,  0.0579,\n",
       "                       -0.0772,  0.0064,  0.0760, -0.0208,  0.0786,  0.0437, -0.0479, -0.0872,\n",
       "                        0.0406,  0.0587, -0.0206,  0.0568,  0.0745,  0.0683,  0.0717,  0.0451,\n",
       "                        0.0505,  0.0162,  0.0872, -0.0036, -0.0333, -0.0648,  0.0467,  0.0030,\n",
       "                       -0.0372, -0.0059, -0.0417, -0.0110,  0.0472,  0.0932,  0.0006,  0.0193,\n",
       "                       -0.0782, -0.0434,  0.0187,  0.0345],\n",
       "                      [ 0.0386, -0.0881, -0.0692,  0.0287,  0.0337,  0.0262,  0.0899,  0.0897,\n",
       "                        0.0170,  0.0181, -0.0243,  0.0516, -0.0694, -0.0633,  0.0235, -0.0255,\n",
       "                       -0.0553, -0.0668, -0.0196,  0.0513,  0.0792, -0.0466, -0.0301,  0.0220,\n",
       "                       -0.0109, -0.0158,  0.0233,  0.0087,  0.0341, -0.0294,  0.0601, -0.0210,\n",
       "                        0.0895,  0.0970, -0.0263, -0.0188, -0.0758, -0.0311, -0.0550, -0.0113,\n",
       "                       -0.0248, -0.0357,  0.0431, -0.0721,  0.0067, -0.0512,  0.0108,  0.0801,\n",
       "                        0.0759,  0.0498,  0.0771, -0.0349,  0.0600, -0.0897, -0.0800, -0.0850,\n",
       "                       -0.0293, -0.0619, -0.0329,  0.0644, -0.0083, -0.0231, -0.0800, -0.0675,\n",
       "                        0.0879, -0.0243, -0.0228,  0.0972,  0.0842, -0.0814,  0.0152, -0.0346,\n",
       "                        0.0076,  0.0261,  0.0188,  0.0867, -0.0495,  0.0578, -0.0345,  0.0570,\n",
       "                       -0.0056,  0.0938,  0.0548, -0.0032,  0.0310, -0.0133, -0.0480,  0.0066,\n",
       "                       -0.0216, -0.0659, -0.0954,  0.0218,  0.0062, -0.0711,  0.0645,  0.0415,\n",
       "                        0.0759, -0.0707, -0.0820,  0.0902]])),\n",
       "             ('layer3.0.bias',\n",
       "              tensor([-0.1000, -0.0192,  0.0037, -0.0739, -0.0736,  0.0933, -0.0545,  0.0212,\n",
       "                      -0.0071, -0.0121]))])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "41f456e6-0da5-4895-b69b-4662c958b9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "24c0b39a-a78b-453e-aa44-19f1ef7d7675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (layer1): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=10, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42658718-9329-4639-83cf-96082646fdee",
   "metadata": {},
   "source": [
    "<h2>3. Pick a loss function and optimizer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2615fb84-4220-4797-9e4e-48e45549a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "torch.optim.SGD\n",
    "torch.optim.Adam\n",
    "\"\"\"\n",
    "learning_rate = 1e-3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5e70d7-978b-42af-b433-9cee68d5de8b",
   "metadata": {},
   "source": [
    "<h2>4. Building training loop</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3188696a-d605-4f1e-a109-abeb7a482320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Epoch 1\n",
      "Epoch 1 / 10, Loss: 0.974820, Accu: 0.693438\n",
      "Epoch 1 / 10, Loss: 0.830420, Accu: 0.738229\n",
      "Epoch 1 / 10, Loss: 0.763204, Accu: 0.761719\n",
      "Finish: 1 Epoch, Loss 0.758417, Accu: 0.763826\n",
      "**********\n",
      "Epoch 2\n",
      "Epoch 2 / 10, Loss: 0.594009, Accu: 0.824323\n",
      "Epoch 2 / 10, Loss: 0.586754, Accu: 0.829792\n",
      "Epoch 2 / 10, Loss: 0.585533, Accu: 0.833264\n",
      "Finish: 2 Epoch, Loss 0.585493, Accu: 0.833406\n",
      "**********\n",
      "Epoch 3\n",
      "Epoch 3 / 10, Loss: 0.557316, Accu: 0.845417\n",
      "Epoch 3 / 10, Loss: 0.549994, Accu: 0.850313\n",
      "Epoch 3 / 10, Loss: 0.549699, Accu: 0.849983\n",
      "Finish: 3 Epoch, Loss 0.549751, Accu: 0.850130\n",
      "**********\n",
      "Epoch 4\n",
      "Epoch 4 / 10, Loss: 0.531917, Accu: 0.857500\n",
      "Epoch 4 / 10, Loss: 0.532628, Accu: 0.860417\n",
      "Epoch 4 / 10, Loss: 0.528948, Accu: 0.861441\n",
      "Finish: 4 Epoch, Loss 0.528152, Accu: 0.861807\n",
      "**********\n",
      "Epoch 5\n",
      "Epoch 5 / 10, Loss: 0.499521, Accu: 0.869531\n",
      "Epoch 5 / 10, Loss: 0.511043, Accu: 0.867448\n",
      "Epoch 5 / 10, Loss: 0.507223, Accu: 0.868594\n",
      "Finish: 5 Epoch, Loss 0.507425, Accu: 0.868770\n",
      "**********\n",
      "Epoch 6\n",
      "Epoch 6 / 10, Loss: 0.487545, Accu: 0.876510\n",
      "Epoch 6 / 10, Loss: 0.492452, Accu: 0.874870\n",
      "Epoch 6 / 10, Loss: 0.492945, Accu: 0.875608\n",
      "Finish: 6 Epoch, Loss 0.492812, Accu: 0.875600\n",
      "**********\n",
      "Epoch 7\n",
      "Epoch 7 / 10, Loss: 0.483442, Accu: 0.880417\n",
      "Epoch 7 / 10, Loss: 0.480103, Accu: 0.879141\n",
      "Epoch 7 / 10, Loss: 0.482006, Accu: 0.879080\n",
      "Finish: 7 Epoch, Loss 0.481129, Accu: 0.878998\n",
      "**********\n",
      "Epoch 8\n",
      "Epoch 8 / 10, Loss: 0.468507, Accu: 0.885156\n",
      "Epoch 8 / 10, Loss: 0.469783, Accu: 0.884792\n",
      "Epoch 8 / 10, Loss: 0.471419, Accu: 0.884566\n",
      "Finish: 8 Epoch, Loss 0.471716, Accu: 0.884945\n",
      "**********\n",
      "Epoch 9\n",
      "Epoch 9 / 10, Loss: 0.458934, Accu: 0.888750\n",
      "Epoch 9 / 10, Loss: 0.456027, Accu: 0.888854\n",
      "Epoch 9 / 10, Loss: 0.460734, Accu: 0.889010\n",
      "Finish: 9 Epoch, Loss 0.461449, Accu: 0.888759\n",
      "**********\n",
      "Epoch 10\n",
      "Epoch 10 / 10, Loss: 0.450060, Accu: 0.895729\n",
      "Epoch 10 / 10, Loss: 0.448096, Accu: 0.895260\n",
      "Epoch 10 / 10, Loss: 0.451506, Accu: 0.894427\n",
      "Finish: 10 Epoch, Loss 0.452084, Accu: 0.894190\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    print('*' * 10)\n",
    "    print(f'Epoch {epoch + 1}')\n",
    "    running_loss = 0.0\n",
    "    running_accu = 0.0\n",
    "    for i,data in enumerate(train_loader,1):\n",
    "        img,label = data\n",
    "        img = img.view(img.size(0),-1)\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        out = model(img)\n",
    "        loss = criterion(out,label)\n",
    "        running_loss += loss.item()\n",
    "        _,pred = torch.max(out,1) #64,10\n",
    "        running_accu += (pred == label).float().mean()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 300 == 0:\n",
    "            print(f'Epoch {epoch + 1} / {num_epochs}, Loss: {running_loss / i:.6f}, Accu: {running_accu / i:.6f}')\n",
    "    print(f'Finish: {epoch + 1} Epoch, Loss {running_loss / i:.6f}, Accu: {running_accu / i:.6f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645197f6-54b0-48c7-9cf0-fc201e219175",
   "metadata": {},
   "source": [
    "<h2>5. Evaluate your model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "407e8f47-f6fb-469c-b7e7-d1661e843346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5487263063621369, Accu: 0.8565883636474609\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "eval_loss = 0.\n",
    "eval_accu = 0.\n",
    "for data in test_loader:\n",
    "    img,label = data\n",
    "    img = img.view(img.size(0),-1)\n",
    "    img = img.to(device)\n",
    "    label = label.to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model(img)\n",
    "        loss = criterion(out,label)\n",
    "        eval_loss += loss.item()\n",
    "        _,pred = torch.max(out,1)\n",
    "        eval_accu += (pred == label).float().mean()\n",
    "print(f'Test loss: {eval_loss / len(test_loader)}, Accu: {eval_accu / len(test_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d06a43-31a5-48ee-8c3c-e5156a53896e",
   "metadata": {},
   "source": [
    "<h2>6. Visualize your model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "95ce8a35-702f-4c66-a9f3-e5206d4057c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images,labels = next(iter(test_loader))\n",
    "images = images.reshape(-1,28*28).to(device)\n",
    "outputs = model(images)\n",
    "_,pred = torch.max(outputs,1)\n",
    "fig,ax = plt.subplots(1,5,figsize=(10,5))\n",
    "for i in range(5):\n",
    "    ax[i].imshow(images[i].reshape(28,28).cpu(),cmap='gray')\n",
    "    ax[i].set_title(f'True: {labels[i].item()}, Pred: {pred[i].item()}')\n",
    "    ax[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a650d9c-8d54-4083-a8a3-7c7f11a2e657",
   "metadata": {},
   "source": [
    "<h2>7. Save the model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "29588894-8842-444c-8e21-8a20f0abf4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'./Classification_with_Neural_Network.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
