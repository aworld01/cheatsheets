{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c193d6e-45bf-4f6b-98bd-b2f2c288c5f9",
   "metadata": {},
   "source": [
    "<h2>2:22:50 / 3:11:52</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b76962-202e-429b-a5ef-b5597ae4a1ba",
   "metadata": {},
   "source": [
    "<h1>Workflow</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d029981d-a7ce-4fbc-8788-d89f7ae961b9",
   "metadata": {},
   "source": [
    "<pre>\n",
    "    0. Import important liberaries\n",
    "    1. Get data ready (turn into tensors and batches)\n",
    "    2. Build a logistic regression model\n",
    "    3. Pick loss function and optimizer\n",
    "    4. Build a training loop\n",
    "    5. Evaluate your model\n",
    "    6. How to improve our model\n",
    "    7. Save your model\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2291e052-aa15-477d-8de3-fc21b3236ae3",
   "metadata": {},
   "source": [
    "<h2>0. Import important liberaries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0fb211fd-5de3-4101-8021-9e0e2db743b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8961fcb1-0c42-491f-bdcd-36a5abee87a5",
   "metadata": {},
   "source": [
    "<h2>1. Get data ready (turn into tensors and batches</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefb117c-0a6a-460f-9984-0d76ffbdaf14",
   "metadata": {},
   "source": [
    "<h3>Download datasets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c392774-4c72-46aa-a7d8-154acd6c5480",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.FashionMNIST(root=\"/dataset\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.FashionMNIST(root=\"/dataset\", train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bee8cda8-33da-414f-b69f-26432c64792d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: /dataset\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2c40f7d5-ea43-4a08-b75f-e53fa654eb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: /dataset\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82564cc9-090b-42db-83b1-1fa13b5a0240",
   "metadata": {},
   "source": [
    "<h2>2. Convert data into batches</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "884206b3-869d-451c-a16b-4d1da1ef45c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1e7f926c-dbbe-41d9-92f8-7f929a91e840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader) # 60000 / 64 = 938"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e580af5d-dfe7-4aeb-b009-f8f090681eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader) #10000 / 64 = 157"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b2aa31-804e-4c83-80f5-ce6fe4effb09",
   "metadata": {},
   "source": [
    "<h2>3. Build logistic model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a1647e3c-6df3-456e-afc1-fb6b6c688d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, in_dim, n_class):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "392d81d3-250f-4c54-b0f5-d2e40a522f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(28*28, 10) #28*28 = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "daac012b-28f8-49f9-844d-487a1e508852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (linear): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "58726021-1931-44dd-9432-1c9d74ea5a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[-0.0035, -0.0194, -0.0144,  ...,  0.0071, -0.0303, -0.0003],\n",
       "                      [ 0.0333, -0.0004, -0.0117,  ..., -0.0281,  0.0276,  0.0096],\n",
       "                      [ 0.0108,  0.0245,  0.0265,  ...,  0.0259, -0.0179, -0.0350],\n",
       "                      ...,\n",
       "                      [-0.0172,  0.0129, -0.0060,  ..., -0.0288, -0.0327,  0.0144],\n",
       "                      [-0.0167, -0.0194,  0.0331,  ...,  0.0124,  0.0064, -0.0158],\n",
       "                      [-0.0319,  0.0171, -0.0208,  ..., -0.0095, -0.0254,  0.0216]])),\n",
       "             ('linear.bias',\n",
       "              tensor([-0.0303,  0.0221,  0.0133,  0.0122,  0.0178, -0.0345, -0.0252, -0.0257,\n",
       "                      -0.0148,  0.0110]))])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "33a21165-1038-41e9-9f39-f8d2e2ca9f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' #Code for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9378d62d-969b-4422-b2a0-c6977cd4ef0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "69a99d17-fab5-4b1c-b470-66f350dba5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device) #Send model to tun at GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be475177-a67f-4a85-99a7-ed14cc6d29f8",
   "metadata": {},
   "source": [
    "<h2>4. Pick a loss function and optimizer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8b09fac3-1299-40b8-af7f-f33c511b29a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3371211b-0dea-42a3-b836-0d3c5bfa9684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0035, -0.0194, -0.0144,  ...,  0.0071, -0.0303, -0.0003],\n",
       "         [ 0.0333, -0.0004, -0.0117,  ..., -0.0281,  0.0276,  0.0096],\n",
       "         [ 0.0108,  0.0245,  0.0265,  ...,  0.0259, -0.0179, -0.0350],\n",
       "         ...,\n",
       "         [-0.0172,  0.0129, -0.0060,  ..., -0.0288, -0.0327,  0.0144],\n",
       "         [-0.0167, -0.0194,  0.0331,  ...,  0.0124,  0.0064, -0.0158],\n",
       "         [-0.0319,  0.0171, -0.0208,  ..., -0.0095, -0.0254,  0.0216]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0303,  0.0221,  0.0133,  0.0122,  0.0178, -0.0345, -0.0252, -0.0257,\n",
       "         -0.0148,  0.0110], device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "00fc0861-30db-46d8-aae0-d3962cdcdd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[-0.0035, -0.0194, -0.0144,  ...,  0.0071, -0.0303, -0.0003],\n",
       "                      [ 0.0333, -0.0004, -0.0117,  ..., -0.0281,  0.0276,  0.0096],\n",
       "                      [ 0.0108,  0.0245,  0.0265,  ...,  0.0259, -0.0179, -0.0350],\n",
       "                      ...,\n",
       "                      [-0.0172,  0.0129, -0.0060,  ..., -0.0288, -0.0327,  0.0144],\n",
       "                      [-0.0167, -0.0194,  0.0331,  ...,  0.0124,  0.0064, -0.0158],\n",
       "                      [-0.0319,  0.0171, -0.0208,  ..., -0.0095, -0.0254,  0.0216]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear.bias',\n",
       "              tensor([-0.0303,  0.0221,  0.0133,  0.0122,  0.0178, -0.0345, -0.0252, -0.0257,\n",
       "                      -0.0148,  0.0110], device='cuda:0'))])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14d340a-8152-4eb2-9dd4-e915d928fb6c",
   "metadata": {},
   "source": [
    "<h2>5. Building a training loop</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d504135e-1ba8-4772-a2d0-ed7d5187f392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* * * * * * * * * * \n",
      "epoch 1\n",
      "[1 / 6], loss: 2.014395, accuracy: 0.379792\n",
      "[1 / 6], loss: 1.834694, accuracy: 0.491771\n",
      "[1 / 6], loss: 1.703800, accuracy: 0.545382\n",
      "Finish 1 epoch, loss: 1.690839, accu: 0.549157\n",
      "* * * * * * * * * * \n",
      "epoch 2\n",
      "[2 / 6], loss: 1.284526, accuracy: 0.672188\n",
      "[2 / 6], loss: 1.240665, accuracy: 0.672161\n",
      "[2 / 6], loss: 1.203443, accuracy: 0.673854\n",
      "Finish 2 epoch, loss: 1.199102, accu: 0.674074\n",
      "* * * * * * * * * * \n",
      "epoch 3\n",
      "[3 / 6], loss: 1.065344, accuracy: 0.685365\n",
      "[3 / 6], loss: 1.044368, accuracy: 0.688490\n",
      "[3 / 6], loss: 1.025352, accuracy: 0.693507\n",
      "Finish 3 epoch, loss: 1.023736, accu: 0.693980\n",
      "* * * * * * * * * * \n",
      "epoch 4\n",
      "[4 / 6], loss: 0.963111, accuracy: 0.701823\n",
      "[4 / 6], loss: 0.943601, accuracy: 0.709453\n",
      "[4 / 6], loss: 0.932389, accuracy: 0.711354\n",
      "Finish 4 epoch, loss: 0.930929, accu: 0.711987\n",
      "* * * * * * * * * * \n",
      "epoch 5\n",
      "[5 / 6], loss: 0.888828, accuracy: 0.724063\n",
      "[5 / 6], loss: 0.878667, accuracy: 0.727109\n",
      "[5 / 6], loss: 0.872378, accuracy: 0.729410\n",
      "Finish 5 epoch, loss: 0.871272, accu: 0.729511\n",
      "* * * * * * * * * * \n",
      "epoch 6\n",
      "[6 / 6], loss: 0.842863, accuracy: 0.736198\n",
      "[6 / 6], loss: 0.839922, accuracy: 0.738516\n",
      "[6 / 6], loss: 0.829653, accuracy: 0.742326\n",
      "Finish 6 epoch, loss: 0.828624, accu: 0.742471\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 6\n",
    "for epoch in range(num_epochs):\n",
    "    print('* ' *10)\n",
    "    print(f'epoch {epoch +1}')\n",
    "    since = time.time()\n",
    "    running_loss = 0.0\n",
    "    running_accu = 0.0\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader, 1): #937\n",
    "        img, label = data\n",
    "        img = img.view(img.size(0),-1)\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        out = model(img) #forward pass\n",
    "        loss = criterion(out, label)\n",
    "        running_loss += loss.item()\n",
    "        _,pred = torch.max(out, 1)\n",
    "        running_accu += (pred == label).float().mean()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() #backward pass\n",
    "        optimizer.step()\n",
    "        if i % 300 == 0:\n",
    "            print(f'[{epoch+1} / {num_epochs}], loss: {running_loss / i:.6f}, accuracy: {running_accu/i:.6f}')\n",
    "    print(f'Finish {epoch+1} epoch, loss: {running_loss/i:.6f}, accu: {running_accu/i:.6f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
