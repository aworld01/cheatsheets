{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ef614f7-82aa-4fe4-a9e2-7b1b4c5dc59f",
   "metadata": {},
   "source": [
    "16:08 / 2:40:20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f166da00-f865-4914-8445-cb1a216dfafe",
   "metadata": {},
   "source": [
    "0 Import important liberaries <br>\n",
    "1 Prepare your data <br>\n",
    "    1.1 Loading datasets <br>\n",
    "    1.2 Tokenize data <br>\n",
    "    1.3 Split data <br>\n",
    "    1.4 Creating vocabulary <br>\n",
    "    1.5 Numericalizing data <br>\n",
    "    1.6 Converting data into tensors <br>\n",
    "    1.7 Creating dataloaders <br>\n",
    "2. Build a model <br>\n",
    "3. Pick a loss function and optimizer <br>\n",
    "4. Training and evaluation loop functions <br>\n",
    "5. Start training loop <br>\n",
    "6. Visulize your model <br>\n",
    "7. Testing model with new sentence (sentiment analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caefdf8d-6d58-4717-9179-9c27525b3d3c",
   "metadata": {},
   "source": [
    "<h2>0 Import important liberaries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd5030c4-34e8-4cc1-a401-9167541758c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\myApps\\anaconda3\\Lib\\site-packages\\torchtext\\data\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import datasets #!pip install datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "from torchtext.data import get_tokenizer\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e83ba51-bb9b-4277-83a1-22bfbd1070f0",
   "metadata": {},
   "source": [
    "<h2>1 Prepare our data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c14ec2b-861b-4122-a3a9-1169add3c551",
   "metadata": {},
   "source": [
    " <h3>1.1 Loading datasets<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7e87935-8401-4218-8af3-2d22e1143aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at C:\\Users\\Abdul Zoha\\.cache\\huggingface\\datasets\\imdb\\plain_text\\0.0.0\\e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Sat Jan 11 11:41:52 2025).\n"
     ]
    }
   ],
   "source": [
    "train_data,test_data = datasets.load_dataset('imdb',split=['train','test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a449938-7464-4a3c-882a-f7c22e4f932e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980ad174-2998-44b4-8b29-5a08be2df541",
   "metadata": {},
   "source": [
    "<h3>1.2 Tokenize data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f31ed360-3f24-47a2-9763-1a6b391cc95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b737135-2ebd-4164-b5dc-277de3c1ef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_example(example,tokenizer,max_length):\n",
    "    tokens = tokenizer(example['text'])[:max_length]\n",
    "    length = len(tokens)\n",
    "    return {'tokens': tokens,'length': length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2664b7e-98a4-43d5-b71c-1fe76f75a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256\n",
    "train_data = train_data.map(\n",
    "    tokenize_example,fn_kwargs={'tokenizer': tokenizer, 'max_length': max_length}\n",
    ")\n",
    "test_data = test_data.map(\n",
    "    tokenize_example,fn_kwargs={'tokenizer': tokenizer,'max_length': max_length}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fa0e95-50d5-4834-8eea-91c1fa0ca9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
