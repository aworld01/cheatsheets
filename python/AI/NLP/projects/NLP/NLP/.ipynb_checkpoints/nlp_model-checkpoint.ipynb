{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6997,
     "status": "ok",
     "timestamp": 1736946252770,
     "user": {
      "displayName": "Abdul Zoha",
      "userId": "02571689914281045390"
     },
     "user_tz": -330
    },
    "id": "UaV7OtjdTMlZ"
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset.json','r') as rf:\n",
    "    intents = json.load(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intents': [{'tag': 'greeting',\n",
       "   'patterns': ['hello', 'hi', 'hey', 'wake up', 'jarvis'],\n",
       "   'responses': ['hello sir',\n",
       "    'how are you sir',\n",
       "    'always for you sir',\n",
       "    'hello',\n",
       "    \"Here's your assistant\"]},\n",
       "  {'tag': 'bye',\n",
       "   'patterns': ['bye', 'see you later', 'goodbye', 'bye bye', 'goodluck'],\n",
       "   'responses': ['bye sir',\n",
       "    'good bye sir',\n",
       "    \"it'll be nice to see you again\",\n",
       "    'see you later',\n",
       "    'goodluck sir']},\n",
       "  {'tag': 'health',\n",
       "   'patterns': ['how are you', 'how are you feeling now', 'are you fine?'],\n",
       "   'responses': ['fine sir', 'perfect', 'cool']}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "tags = []\n",
    "xy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tp import tokenize, stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for intent in intents['intents']:\n",
    "    tag = intent['tag']\n",
    "    tags.append(tag)\n",
    "    for pattern in intent['patterns']:\n",
    "        w = tokenize(pattern)\n",
    "        all_words.extend(w)\n",
    "        xy.append((w,tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'hi', 'hey', 'wake', 'up', 'jarvis', 'bye', 'see', 'you', 'later', 'goodbye', 'bye', 'bye', 'goodluck', 'how', 'are', 'you', 'how', 'are', 'you', 'feeling', 'now', 'are', 'you', 'fine', '?']\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "print(all_words)\n",
    "print(len(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_words = ['?','!',',','.']\n",
    "all_words = [stem(w) for w in all_words if w not in ignore_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'hi', 'hey', 'wake', 'up', 'jarvi', 'bye', 'see', 'you', 'later', 'goodby', 'bye', 'bye', 'goodluck', 'how', 'are', 'you', 'how', 'are', 'you', 'feel', 'now', 'are', 'you', 'fine']\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(all_words)\n",
    "print(len(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = sorted(set(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['are', 'bye', 'feel', 'fine', 'goodby', 'goodluck', 'hello', 'hey', 'hi', 'how', 'jarvi', 'later', 'now', 'see', 'up', 'wake', 'you']\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "print(all_words)\n",
    "print(len(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['greeting', 'bye', 'health']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bye', 'greeting', 'health']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = sorted(set(tags))\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['hello'], 'greeting'),\n",
       " (['hi'], 'greeting'),\n",
       " (['hey'], 'greeting'),\n",
       " (['wake', 'up'], 'greeting'),\n",
       " (['jarvis'], 'greeting'),\n",
       " (['bye'], 'bye'),\n",
       " (['see', 'you', 'later'], 'bye'),\n",
       " (['goodbye'], 'bye'),\n",
       " (['bye', 'bye'], 'bye'),\n",
       " (['goodluck'], 'bye'),\n",
       " (['how', 'are', 'you'], 'health'),\n",
       " (['how', 'are', 'you', 'feeling', 'now'], 'health'),\n",
       " (['are', 'you', 'fine', '?'], 'health')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bow import BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in xy:\n",
    "    bag = BoW(x,all_words)\n",
    "    x_train.append(bag)\n",
    "\n",
    "    label = tags.index(tag)\n",
    "    y_train.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
      "      dtype=float32), array([1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.],\n",
      "      dtype=float32), array([1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 634,
     "status": "ok",
     "timestamp": 1736946921232,
     "user": {
      "displayName": "Abdul Zoha",
      "userId": "02571689914281045390"
     },
     "user_tz": -330
    },
    "id": "Z7xB6M8kFd5Q"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "hidden_size = 8\n",
    "learning_rate = 0.001\n",
    "input_size = len(x_train[0])\n",
    "num_epochs = 1000\n",
    "output_size = len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "8\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(input_size)\n",
    "print(hidden_size)\n",
    "print(output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(x_train)\n",
    "        self.x_data = x_train\n",
    "        self.y_data = y_train\n",
    "    def __getitem__(self,index):\n",
    "        return self.x_data[index],self.y_data[index]\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChatDataset()\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuron import NeuralNet\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size,hidden_size,output_size).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (l1): Linear(in_features=17, out_features=8, bias=True)\n",
       "  (l2): Linear(in_features=8, out_features=8, bias=True)\n",
       "  (l3): Linear(in_features=8, out_features=3, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss=1.5310\n",
      "final loss=1.5197\n",
      "final loss=1.5180\n",
      "final loss=1.5002\n",
      "final loss=1.4960\n",
      "final loss=1.4902\n",
      "final loss=1.4784\n",
      "final loss=1.4720\n",
      "final loss=1.4596\n",
      "final loss=1.4522\n",
      "final loss=1.4461\n",
      "final loss=1.4367\n",
      "final loss=1.4297\n",
      "final loss=1.4213\n",
      "final loss=1.4152\n",
      "final loss=1.4038\n",
      "final loss=1.4006\n",
      "final loss=1.3895\n",
      "final loss=1.3850\n",
      "final loss=1.3763\n",
      "final loss=1.3642\n",
      "final loss=1.3543\n",
      "final loss=1.3536\n",
      "final loss=1.3495\n",
      "final loss=1.3381\n",
      "final loss=1.3330\n",
      "final loss=1.3267\n",
      "final loss=1.3143\n",
      "final loss=1.3133\n",
      "final loss=1.2989\n",
      "final loss=1.2918\n",
      "final loss=1.2835\n",
      "final loss=1.2798\n",
      "final loss=1.2757\n",
      "final loss=1.2659\n",
      "final loss=1.2578\n",
      "final loss=1.2524\n",
      "final loss=1.2445\n",
      "final loss=1.2443\n",
      "final loss=1.2396\n",
      "final loss=1.2358\n",
      "final loss=1.2197\n",
      "final loss=1.2238\n",
      "final loss=1.2065\n",
      "final loss=1.2078\n",
      "final loss=1.1968\n",
      "final loss=1.1896\n",
      "final loss=1.1812\n",
      "final loss=1.1862\n",
      "final loss=1.1655\n",
      "final loss=1.1587\n",
      "final loss=1.1616\n",
      "final loss=1.1610\n",
      "final loss=1.1467\n",
      "final loss=1.1388\n",
      "final loss=1.1232\n",
      "final loss=1.1278\n",
      "final loss=1.1019\n",
      "final loss=1.1195\n",
      "final loss=1.1054\n",
      "final loss=1.1013\n",
      "final loss=1.0929\n",
      "final loss=1.0620\n",
      "final loss=1.0664\n",
      "final loss=1.0371\n",
      "final loss=1.0264\n",
      "final loss=1.0610\n",
      "final loss=1.0110\n",
      "final loss=1.0164\n",
      "final loss=1.0075\n",
      "final loss=0.9893\n",
      "final loss=1.0057\n",
      "final loss=0.9574\n",
      "final loss=0.9678\n",
      "final loss=0.9636\n",
      "final loss=0.9297\n",
      "final loss=0.9062\n",
      "final loss=0.9070\n",
      "final loss=0.9168\n",
      "final loss=0.8505\n",
      "final loss=0.9069\n",
      "final loss=0.9123\n",
      "final loss=0.8576\n",
      "final loss=0.8204\n",
      "final loss=0.8156\n",
      "final loss=0.8153\n",
      "final loss=0.7955\n",
      "final loss=0.7913\n",
      "final loss=0.7243\n",
      "final loss=0.7619\n",
      "final loss=0.7267\n",
      "final loss=0.7734\n",
      "final loss=0.7515\n",
      "final loss=0.6847\n",
      "final loss=0.7321\n",
      "final loss=0.7493\n",
      "final loss=0.6441\n",
      "final loss=0.6960\n",
      "final loss=0.6670\n",
      "epoch [100]/1000, loss=0.5943\n",
      "final loss=0.5943\n",
      "final loss=0.6513\n",
      "final loss=0.5979\n",
      "final loss=0.5245\n",
      "final loss=0.6248\n",
      "final loss=0.5253\n",
      "final loss=0.4581\n",
      "final loss=0.5524\n",
      "final loss=0.4501\n",
      "final loss=0.4642\n",
      "final loss=0.4686\n",
      "final loss=0.5224\n",
      "final loss=0.4844\n",
      "final loss=0.3902\n",
      "final loss=0.3352\n",
      "final loss=0.3692\n",
      "final loss=0.3818\n",
      "final loss=0.4456\n",
      "final loss=0.4365\n",
      "final loss=0.3920\n",
      "final loss=0.3869\n",
      "final loss=0.3804\n",
      "final loss=0.3532\n",
      "final loss=0.3990\n",
      "final loss=0.3115\n",
      "final loss=0.2496\n",
      "final loss=0.3244\n",
      "final loss=0.3002\n",
      "final loss=0.2946\n",
      "final loss=0.2416\n",
      "final loss=0.2401\n",
      "final loss=0.2151\n",
      "final loss=0.2805\n",
      "final loss=0.1712\n",
      "final loss=0.2217\n",
      "final loss=0.1663\n",
      "final loss=0.1405\n",
      "final loss=0.1675\n",
      "final loss=0.1423\n",
      "final loss=0.2161\n",
      "final loss=0.1477\n",
      "final loss=0.1395\n",
      "final loss=0.1918\n",
      "final loss=0.1763\n",
      "final loss=0.1237\n",
      "final loss=0.1578\n",
      "final loss=0.1503\n",
      "final loss=0.1544\n",
      "final loss=0.1522\n",
      "final loss=0.1481\n",
      "final loss=0.1400\n",
      "final loss=0.1138\n",
      "final loss=0.1332\n",
      "final loss=0.1579\n",
      "final loss=0.1104\n",
      "final loss=0.1130\n",
      "final loss=0.0786\n",
      "final loss=0.1286\n",
      "final loss=0.1371\n",
      "final loss=0.0955\n",
      "final loss=0.1214\n",
      "final loss=0.0891\n",
      "final loss=0.1210\n",
      "final loss=0.0678\n",
      "final loss=0.0661\n",
      "final loss=0.0980\n",
      "final loss=0.0837\n",
      "final loss=0.0722\n",
      "final loss=0.0584\n",
      "final loss=0.0791\n",
      "final loss=0.0674\n",
      "final loss=0.0552\n",
      "final loss=0.0716\n",
      "final loss=0.1090\n",
      "final loss=0.0504\n",
      "final loss=0.0710\n",
      "final loss=0.0676\n",
      "final loss=0.0792\n",
      "final loss=0.0699\n",
      "final loss=0.0512\n",
      "final loss=0.0693\n",
      "final loss=0.0690\n",
      "final loss=0.0365\n",
      "final loss=0.0620\n",
      "final loss=0.0691\n",
      "final loss=0.0570\n",
      "final loss=0.0526\n",
      "final loss=0.0396\n",
      "final loss=0.0538\n",
      "final loss=0.0447\n",
      "final loss=0.0466\n",
      "final loss=0.0458\n",
      "final loss=0.0544\n",
      "final loss=0.0471\n",
      "final loss=0.0577\n",
      "final loss=0.0457\n",
      "final loss=0.0456\n",
      "final loss=0.0269\n",
      "final loss=0.0561\n",
      "final loss=0.0574\n",
      "epoch [200]/1000, loss=0.0517\n",
      "final loss=0.0517\n",
      "final loss=0.0344\n",
      "final loss=0.0313\n",
      "final loss=0.0327\n",
      "final loss=0.0317\n",
      "final loss=0.0400\n",
      "final loss=0.0288\n",
      "final loss=0.0169\n",
      "final loss=0.0432\n",
      "final loss=0.0322\n",
      "final loss=0.0315\n",
      "final loss=0.0374\n",
      "final loss=0.0329\n",
      "final loss=0.0287\n",
      "final loss=0.0169\n",
      "final loss=0.0285\n",
      "final loss=0.0223\n",
      "final loss=0.0284\n",
      "final loss=0.0242\n",
      "final loss=0.0281\n",
      "final loss=0.0337\n",
      "final loss=0.0206\n",
      "final loss=0.0311\n",
      "final loss=0.0221\n",
      "final loss=0.0315\n",
      "final loss=0.0165\n",
      "final loss=0.0220\n",
      "final loss=0.0233\n",
      "final loss=0.0320\n",
      "final loss=0.0168\n",
      "final loss=0.0152\n",
      "final loss=0.0146\n",
      "final loss=0.0172\n",
      "final loss=0.0091\n",
      "final loss=0.0151\n",
      "final loss=0.0199\n",
      "final loss=0.0270\n",
      "final loss=0.0249\n",
      "final loss=0.0158\n",
      "final loss=0.0128\n",
      "final loss=0.0251\n",
      "final loss=0.0259\n",
      "final loss=0.0187\n",
      "final loss=0.0196\n",
      "final loss=0.0187\n",
      "final loss=0.0233\n",
      "final loss=0.0155\n",
      "final loss=0.0186\n",
      "final loss=0.0173\n",
      "final loss=0.0137\n",
      "final loss=0.0234\n",
      "final loss=0.0110\n",
      "final loss=0.0096\n",
      "final loss=0.0227\n",
      "final loss=0.0112\n",
      "final loss=0.0122\n",
      "final loss=0.0166\n",
      "final loss=0.0142\n",
      "final loss=0.0190\n",
      "final loss=0.0229\n",
      "final loss=0.0131\n",
      "final loss=0.0097\n",
      "final loss=0.0131\n",
      "final loss=0.0183\n",
      "final loss=0.0138\n",
      "final loss=0.0170\n",
      "final loss=0.0071\n",
      "final loss=0.0160\n",
      "final loss=0.0169\n",
      "final loss=0.0174\n",
      "final loss=0.0112\n",
      "final loss=0.0130\n",
      "final loss=0.0159\n",
      "final loss=0.0133\n",
      "final loss=0.0191\n",
      "final loss=0.0128\n",
      "final loss=0.0147\n",
      "final loss=0.0130\n",
      "final loss=0.0143\n",
      "final loss=0.0186\n",
      "final loss=0.0153\n",
      "final loss=0.0146\n",
      "final loss=0.0130\n",
      "final loss=0.0112\n",
      "final loss=0.0126\n",
      "final loss=0.0121\n",
      "final loss=0.0098\n",
      "final loss=0.0110\n",
      "final loss=0.0149\n",
      "final loss=0.0144\n",
      "final loss=0.0151\n",
      "final loss=0.0162\n",
      "final loss=0.0174\n",
      "final loss=0.0055\n",
      "final loss=0.0078\n",
      "final loss=0.0117\n",
      "final loss=0.0067\n",
      "final loss=0.0115\n",
      "final loss=0.0088\n",
      "final loss=0.0104\n",
      "epoch [300]/1000, loss=0.0076\n",
      "final loss=0.0076\n",
      "final loss=0.0116\n",
      "final loss=0.0122\n",
      "final loss=0.0077\n",
      "final loss=0.0066\n",
      "final loss=0.0123\n",
      "final loss=0.0110\n",
      "final loss=0.0068\n",
      "final loss=0.0105\n",
      "final loss=0.0061\n",
      "final loss=0.0100\n",
      "final loss=0.0101\n",
      "final loss=0.0109\n",
      "final loss=0.0147\n",
      "final loss=0.0101\n",
      "final loss=0.0054\n",
      "final loss=0.0080\n",
      "final loss=0.0075\n",
      "final loss=0.0098\n",
      "final loss=0.0108\n",
      "final loss=0.0072\n",
      "final loss=0.0106\n",
      "final loss=0.0063\n",
      "final loss=0.0090\n",
      "final loss=0.0093\n",
      "final loss=0.0104\n",
      "final loss=0.0072\n",
      "final loss=0.0061\n",
      "final loss=0.0085\n",
      "final loss=0.0060\n",
      "final loss=0.0058\n",
      "final loss=0.0083\n",
      "final loss=0.0086\n",
      "final loss=0.0082\n",
      "final loss=0.0095\n",
      "final loss=0.0094\n",
      "final loss=0.0076\n",
      "final loss=0.0097\n",
      "final loss=0.0061\n",
      "final loss=0.0072\n",
      "final loss=0.0091\n",
      "final loss=0.0071\n",
      "final loss=0.0093\n",
      "final loss=0.0081\n",
      "final loss=0.0054\n",
      "final loss=0.0074\n",
      "final loss=0.0081\n",
      "final loss=0.0069\n",
      "final loss=0.0074\n",
      "final loss=0.0047\n",
      "final loss=0.0055\n",
      "final loss=0.0043\n",
      "final loss=0.0048\n",
      "final loss=0.0036\n",
      "final loss=0.0081\n",
      "final loss=0.0070\n",
      "final loss=0.0075\n",
      "final loss=0.0077\n",
      "final loss=0.0040\n",
      "final loss=0.0085\n",
      "final loss=0.0051\n",
      "final loss=0.0053\n",
      "final loss=0.0064\n",
      "final loss=0.0039\n",
      "final loss=0.0033\n",
      "final loss=0.0070\n",
      "final loss=0.0077\n",
      "final loss=0.0064\n",
      "final loss=0.0072\n",
      "final loss=0.0052\n",
      "final loss=0.0064\n",
      "final loss=0.0048\n",
      "final loss=0.0053\n",
      "final loss=0.0036\n",
      "final loss=0.0054\n",
      "final loss=0.0067\n",
      "final loss=0.0049\n",
      "final loss=0.0040\n",
      "final loss=0.0037\n",
      "final loss=0.0055\n",
      "final loss=0.0052\n",
      "final loss=0.0054\n",
      "final loss=0.0043\n",
      "final loss=0.0052\n",
      "final loss=0.0042\n",
      "final loss=0.0043\n",
      "final loss=0.0049\n",
      "final loss=0.0036\n",
      "final loss=0.0023\n",
      "final loss=0.0052\n",
      "final loss=0.0032\n",
      "final loss=0.0051\n",
      "final loss=0.0046\n",
      "final loss=0.0034\n",
      "final loss=0.0046\n",
      "final loss=0.0058\n",
      "final loss=0.0050\n",
      "final loss=0.0036\n",
      "final loss=0.0047\n",
      "final loss=0.0058\n",
      "epoch [400]/1000, loss=0.0039\n",
      "final loss=0.0039\n",
      "final loss=0.0032\n",
      "final loss=0.0046\n",
      "final loss=0.0041\n",
      "final loss=0.0040\n",
      "final loss=0.0046\n",
      "final loss=0.0029\n",
      "final loss=0.0064\n",
      "final loss=0.0055\n",
      "final loss=0.0051\n",
      "final loss=0.0051\n",
      "final loss=0.0053\n",
      "final loss=0.0029\n",
      "final loss=0.0027\n",
      "final loss=0.0016\n",
      "final loss=0.0050\n",
      "final loss=0.0041\n",
      "final loss=0.0034\n",
      "final loss=0.0029\n",
      "final loss=0.0027\n",
      "final loss=0.0047\n",
      "final loss=0.0055\n",
      "final loss=0.0046\n",
      "final loss=0.0034\n",
      "final loss=0.0022\n",
      "final loss=0.0044\n",
      "final loss=0.0028\n",
      "final loss=0.0049\n",
      "final loss=0.0051\n",
      "final loss=0.0038\n",
      "final loss=0.0031\n",
      "final loss=0.0017\n",
      "final loss=0.0040\n",
      "final loss=0.0020\n",
      "final loss=0.0031\n",
      "final loss=0.0035\n",
      "final loss=0.0047\n",
      "final loss=0.0025\n",
      "final loss=0.0026\n",
      "final loss=0.0027\n",
      "final loss=0.0034\n",
      "final loss=0.0030\n",
      "final loss=0.0042\n",
      "final loss=0.0026\n",
      "final loss=0.0035\n",
      "final loss=0.0037\n",
      "final loss=0.0036\n",
      "final loss=0.0024\n",
      "final loss=0.0029\n",
      "final loss=0.0041\n",
      "final loss=0.0029\n",
      "final loss=0.0032\n",
      "final loss=0.0048\n",
      "final loss=0.0031\n",
      "final loss=0.0047\n",
      "final loss=0.0031\n",
      "final loss=0.0036\n",
      "final loss=0.0019\n",
      "final loss=0.0032\n",
      "final loss=0.0036\n",
      "final loss=0.0033\n",
      "final loss=0.0031\n",
      "final loss=0.0028\n",
      "final loss=0.0029\n",
      "final loss=0.0042\n",
      "final loss=0.0030\n",
      "final loss=0.0031\n",
      "final loss=0.0025\n",
      "final loss=0.0033\n",
      "final loss=0.0019\n",
      "final loss=0.0034\n",
      "final loss=0.0021\n",
      "final loss=0.0030\n",
      "final loss=0.0030\n",
      "final loss=0.0029\n",
      "final loss=0.0030\n",
      "final loss=0.0028\n",
      "final loss=0.0030\n",
      "final loss=0.0033\n",
      "final loss=0.0022\n",
      "final loss=0.0017\n",
      "final loss=0.0014\n",
      "final loss=0.0037\n",
      "final loss=0.0036\n",
      "final loss=0.0025\n",
      "final loss=0.0033\n",
      "final loss=0.0030\n",
      "final loss=0.0035\n",
      "final loss=0.0023\n",
      "final loss=0.0034\n",
      "final loss=0.0035\n",
      "final loss=0.0031\n",
      "final loss=0.0026\n",
      "final loss=0.0029\n",
      "final loss=0.0023\n",
      "final loss=0.0022\n",
      "final loss=0.0019\n",
      "final loss=0.0032\n",
      "final loss=0.0023\n",
      "final loss=0.0034\n",
      "epoch [500]/1000, loss=0.0020\n",
      "final loss=0.0020\n",
      "final loss=0.0033\n",
      "final loss=0.0033\n",
      "final loss=0.0023\n",
      "final loss=0.0027\n",
      "final loss=0.0032\n",
      "final loss=0.0030\n",
      "final loss=0.0022\n",
      "final loss=0.0028\n",
      "final loss=0.0028\n",
      "final loss=0.0029\n",
      "final loss=0.0037\n",
      "final loss=0.0020\n",
      "final loss=0.0017\n",
      "final loss=0.0026\n",
      "final loss=0.0029\n",
      "final loss=0.0035\n",
      "final loss=0.0020\n",
      "final loss=0.0022\n",
      "final loss=0.0023\n",
      "final loss=0.0021\n",
      "final loss=0.0022\n",
      "final loss=0.0016\n",
      "final loss=0.0027\n",
      "final loss=0.0027\n",
      "final loss=0.0014\n",
      "final loss=0.0028\n",
      "final loss=0.0013\n",
      "final loss=0.0014\n",
      "final loss=0.0019\n",
      "final loss=0.0019\n",
      "final loss=0.0028\n",
      "final loss=0.0016\n",
      "final loss=0.0025\n",
      "final loss=0.0018\n",
      "final loss=0.0018\n",
      "final loss=0.0020\n",
      "final loss=0.0016\n",
      "final loss=0.0029\n",
      "final loss=0.0028\n",
      "final loss=0.0022\n",
      "final loss=0.0020\n",
      "final loss=0.0017\n",
      "final loss=0.0014\n",
      "final loss=0.0027\n",
      "final loss=0.0023\n",
      "final loss=0.0022\n",
      "final loss=0.0025\n",
      "final loss=0.0019\n",
      "final loss=0.0026\n",
      "final loss=0.0020\n",
      "final loss=0.0018\n",
      "final loss=0.0023\n",
      "final loss=0.0018\n",
      "final loss=0.0024\n",
      "final loss=0.0014\n",
      "final loss=0.0028\n",
      "final loss=0.0017\n",
      "final loss=0.0017\n",
      "final loss=0.0022\n",
      "final loss=0.0017\n",
      "final loss=0.0018\n",
      "final loss=0.0016\n",
      "final loss=0.0024\n",
      "final loss=0.0017\n",
      "final loss=0.0015\n",
      "final loss=0.0018\n",
      "final loss=0.0016\n",
      "final loss=0.0018\n",
      "final loss=0.0025\n",
      "final loss=0.0014\n",
      "final loss=0.0023\n",
      "final loss=0.0019\n",
      "final loss=0.0022\n",
      "final loss=0.0020\n",
      "final loss=0.0015\n",
      "final loss=0.0018\n",
      "final loss=0.0022\n",
      "final loss=0.0022\n",
      "final loss=0.0008\n",
      "final loss=0.0016\n",
      "final loss=0.0015\n",
      "final loss=0.0015\n",
      "final loss=0.0014\n",
      "final loss=0.0013\n",
      "final loss=0.0017\n",
      "final loss=0.0021\n",
      "final loss=0.0015\n",
      "final loss=0.0006\n",
      "final loss=0.0019\n",
      "final loss=0.0015\n",
      "final loss=0.0011\n",
      "final loss=0.0017\n",
      "final loss=0.0008\n",
      "final loss=0.0022\n",
      "final loss=0.0024\n",
      "final loss=0.0018\n",
      "final loss=0.0017\n",
      "final loss=0.0016\n",
      "final loss=0.0018\n",
      "epoch [600]/1000, loss=0.0013\n",
      "final loss=0.0013\n",
      "final loss=0.0017\n",
      "final loss=0.0016\n",
      "final loss=0.0020\n",
      "final loss=0.0015\n",
      "final loss=0.0017\n",
      "final loss=0.0014\n",
      "final loss=0.0016\n",
      "final loss=0.0010\n",
      "final loss=0.0012\n",
      "final loss=0.0016\n",
      "final loss=0.0016\n",
      "final loss=0.0016\n",
      "final loss=0.0016\n",
      "final loss=0.0024\n",
      "final loss=0.0012\n",
      "final loss=0.0022\n",
      "final loss=0.0015\n",
      "final loss=0.0017\n",
      "final loss=0.0021\n",
      "final loss=0.0013\n",
      "final loss=0.0012\n",
      "final loss=0.0010\n",
      "final loss=0.0022\n",
      "final loss=0.0015\n",
      "final loss=0.0014\n",
      "final loss=0.0018\n",
      "final loss=0.0015\n",
      "final loss=0.0011\n",
      "final loss=0.0023\n",
      "final loss=0.0002\n",
      "final loss=0.0021\n",
      "final loss=0.0010\n",
      "final loss=0.0007\n",
      "final loss=0.0017\n",
      "final loss=0.0014\n",
      "final loss=0.0011\n",
      "final loss=0.0019\n",
      "final loss=0.0013\n",
      "final loss=0.0008\n",
      "final loss=0.0015\n",
      "final loss=0.0014\n",
      "final loss=0.0010\n",
      "final loss=0.0018\n",
      "final loss=0.0015\n",
      "final loss=0.0012\n",
      "final loss=0.0013\n",
      "final loss=0.0009\n",
      "final loss=0.0014\n",
      "final loss=0.0015\n",
      "final loss=0.0016\n",
      "final loss=0.0015\n",
      "final loss=0.0011\n",
      "final loss=0.0013\n",
      "final loss=0.0015\n",
      "final loss=0.0008\n",
      "final loss=0.0008\n",
      "final loss=0.0009\n",
      "final loss=0.0008\n",
      "final loss=0.0017\n",
      "final loss=0.0017\n",
      "final loss=0.0013\n",
      "final loss=0.0009\n",
      "final loss=0.0018\n",
      "final loss=0.0012\n",
      "final loss=0.0011\n",
      "final loss=0.0016\n",
      "final loss=0.0013\n",
      "final loss=0.0014\n",
      "final loss=0.0013\n",
      "final loss=0.0015\n",
      "final loss=0.0017\n",
      "final loss=0.0011\n",
      "final loss=0.0015\n",
      "final loss=0.0015\n",
      "final loss=0.0007\n",
      "final loss=0.0011\n",
      "final loss=0.0012\n",
      "final loss=0.0008\n",
      "final loss=0.0011\n",
      "final loss=0.0015\n",
      "final loss=0.0018\n",
      "final loss=0.0012\n",
      "final loss=0.0013\n",
      "final loss=0.0013\n",
      "final loss=0.0013\n",
      "final loss=0.0013\n",
      "final loss=0.0011\n",
      "final loss=0.0015\n",
      "final loss=0.0010\n",
      "final loss=0.0019\n",
      "final loss=0.0017\n",
      "final loss=0.0008\n",
      "final loss=0.0011\n",
      "final loss=0.0011\n",
      "final loss=0.0007\n",
      "final loss=0.0012\n",
      "final loss=0.0005\n",
      "final loss=0.0011\n",
      "final loss=0.0015\n",
      "epoch [700]/1000, loss=0.0011\n",
      "final loss=0.0011\n",
      "final loss=0.0016\n",
      "final loss=0.0013\n",
      "final loss=0.0014\n",
      "final loss=0.0010\n",
      "final loss=0.0008\n",
      "final loss=0.0003\n",
      "final loss=0.0010\n",
      "final loss=0.0011\n",
      "final loss=0.0003\n",
      "final loss=0.0013\n",
      "final loss=0.0008\n",
      "final loss=0.0010\n",
      "final loss=0.0010\n",
      "final loss=0.0005\n",
      "final loss=0.0007\n",
      "final loss=0.0010\n",
      "final loss=0.0009\n",
      "final loss=0.0010\n",
      "final loss=0.0015\n",
      "final loss=0.0006\n",
      "final loss=0.0013\n",
      "final loss=0.0006\n",
      "final loss=0.0010\n",
      "final loss=0.0010\n",
      "final loss=0.0013\n",
      "final loss=0.0013\n",
      "final loss=0.0008\n",
      "final loss=0.0010\n",
      "final loss=0.0010\n",
      "final loss=0.0012\n",
      "final loss=0.0007\n",
      "final loss=0.0012\n",
      "final loss=0.0004\n",
      "final loss=0.0009\n",
      "final loss=0.0005\n",
      "final loss=0.0014\n",
      "final loss=0.0013\n",
      "final loss=0.0010\n",
      "final loss=0.0008\n",
      "final loss=0.0013\n",
      "final loss=0.0013\n",
      "final loss=0.0010\n",
      "final loss=0.0010\n",
      "final loss=0.0012\n",
      "final loss=0.0010\n",
      "final loss=0.0003\n",
      "final loss=0.0010\n",
      "final loss=0.0006\n",
      "final loss=0.0010\n",
      "final loss=0.0006\n",
      "final loss=0.0006\n",
      "final loss=0.0007\n",
      "final loss=0.0012\n",
      "final loss=0.0012\n",
      "final loss=0.0008\n",
      "final loss=0.0003\n",
      "final loss=0.0007\n",
      "final loss=0.0007\n",
      "final loss=0.0010\n",
      "final loss=0.0004\n",
      "final loss=0.0008\n",
      "final loss=0.0007\n",
      "final loss=0.0008\n",
      "final loss=0.0011\n",
      "final loss=0.0008\n",
      "final loss=0.0012\n",
      "final loss=0.0009\n",
      "final loss=0.0013\n",
      "final loss=0.0012\n",
      "final loss=0.0008\n",
      "final loss=0.0009\n",
      "final loss=0.0014\n",
      "final loss=0.0009\n",
      "final loss=0.0009\n",
      "final loss=0.0009\n",
      "final loss=0.0010\n",
      "final loss=0.0012\n",
      "final loss=0.0011\n",
      "final loss=0.0009\n",
      "final loss=0.0008\n",
      "final loss=0.0005\n",
      "final loss=0.0012\n",
      "final loss=0.0010\n",
      "final loss=0.0010\n",
      "final loss=0.0006\n",
      "final loss=0.0010\n",
      "final loss=0.0006\n",
      "final loss=0.0008\n",
      "final loss=0.0009\n",
      "final loss=0.0011\n",
      "final loss=0.0006\n",
      "final loss=0.0005\n",
      "final loss=0.0004\n",
      "final loss=0.0008\n",
      "final loss=0.0010\n",
      "final loss=0.0006\n",
      "final loss=0.0007\n",
      "final loss=0.0008\n",
      "final loss=0.0002\n",
      "epoch [800]/1000, loss=0.0008\n",
      "final loss=0.0008\n",
      "final loss=0.0009\n",
      "final loss=0.0010\n",
      "final loss=0.0006\n",
      "final loss=0.0008\n",
      "final loss=0.0004\n",
      "final loss=0.0009\n",
      "final loss=0.0006\n",
      "final loss=0.0009\n",
      "final loss=0.0007\n",
      "final loss=0.0006\n",
      "final loss=0.0011\n",
      "final loss=0.0005\n",
      "final loss=0.0008\n",
      "final loss=0.0007\n",
      "final loss=0.0009\n",
      "final loss=0.0007\n",
      "final loss=0.0005\n",
      "final loss=0.0008\n",
      "final loss=0.0006\n",
      "final loss=0.0007\n",
      "final loss=0.0007\n",
      "final loss=0.0010\n",
      "final loss=0.0005\n",
      "final loss=0.0007\n",
      "final loss=0.0004\n",
      "final loss=0.0008\n",
      "final loss=0.0006\n",
      "final loss=0.0010\n",
      "final loss=0.0006\n",
      "final loss=0.0007\n",
      "final loss=0.0008\n",
      "final loss=0.0006\n",
      "final loss=0.0008\n",
      "final loss=0.0007\n",
      "final loss=0.0009\n",
      "final loss=0.0007\n",
      "final loss=0.0009\n",
      "final loss=0.0006\n",
      "final loss=0.0008\n",
      "final loss=0.0008\n",
      "final loss=0.0006\n",
      "final loss=0.0006\n",
      "final loss=0.0007\n",
      "final loss=0.0008\n",
      "final loss=0.0009\n",
      "final loss=0.0009\n",
      "final loss=0.0007\n",
      "final loss=0.0010\n",
      "final loss=0.0007\n",
      "final loss=0.0008\n",
      "final loss=0.0008\n",
      "final loss=0.0005\n",
      "final loss=0.0005\n",
      "final loss=0.0009\n",
      "final loss=0.0005\n",
      "final loss=0.0004\n",
      "final loss=0.0006\n",
      "final loss=0.0007\n",
      "final loss=0.0007\n",
      "final loss=0.0008\n",
      "final loss=0.0007\n",
      "final loss=0.0006\n",
      "final loss=0.0008\n",
      "final loss=0.0007\n",
      "final loss=0.0005\n",
      "final loss=0.0005\n",
      "final loss=0.0008\n",
      "final loss=0.0003\n",
      "final loss=0.0008\n",
      "final loss=0.0007\n",
      "final loss=0.0007\n",
      "final loss=0.0007\n",
      "final loss=0.0006\n",
      "final loss=0.0006\n",
      "final loss=0.0010\n",
      "final loss=0.0011\n",
      "final loss=0.0007\n",
      "final loss=0.0004\n",
      "final loss=0.0009\n",
      "final loss=0.0003\n",
      "final loss=0.0005\n",
      "final loss=0.0007\n",
      "final loss=0.0002\n",
      "final loss=0.0003\n",
      "final loss=0.0009\n",
      "final loss=0.0007\n",
      "final loss=0.0006\n",
      "final loss=0.0009\n",
      "final loss=0.0007\n",
      "final loss=0.0007\n",
      "final loss=0.0008\n",
      "final loss=0.0005\n",
      "final loss=0.0005\n",
      "final loss=0.0004\n",
      "final loss=0.0008\n",
      "final loss=0.0003\n",
      "final loss=0.0004\n",
      "final loss=0.0006\n",
      "final loss=0.0006\n",
      "epoch [900]/1000, loss=0.0006\n",
      "final loss=0.0006\n",
      "final loss=0.0004\n",
      "final loss=0.0008\n",
      "final loss=0.0007\n",
      "final loss=0.0006\n",
      "final loss=0.0005\n",
      "final loss=0.0005\n",
      "final loss=0.0005\n",
      "final loss=0.0007\n",
      "final loss=0.0006\n",
      "final loss=0.0003\n",
      "final loss=0.0009\n",
      "final loss=0.0006\n",
      "final loss=0.0005\n",
      "final loss=0.0010\n",
      "final loss=0.0005\n",
      "final loss=0.0005\n",
      "final loss=0.0004\n",
      "final loss=0.0003\n",
      "final loss=0.0008\n",
      "final loss=0.0002\n",
      "final loss=0.0005\n",
      "final loss=0.0006\n",
      "final loss=0.0005\n",
      "final loss=0.0005\n",
      "final loss=0.0005\n",
      "final loss=0.0005\n",
      "final loss=0.0005\n",
      "final loss=0.0007\n",
      "final loss=0.0007\n",
      "final loss=0.0004\n",
      "final loss=0.0007\n",
      "final loss=0.0008\n",
      "final loss=0.0005\n",
      "final loss=0.0006\n",
      "final loss=0.0007\n",
      "final loss=0.0006\n",
      "final loss=0.0004\n",
      "final loss=0.0006\n",
      "final loss=0.0005\n",
      "final loss=0.0005\n",
      "final loss=0.0007\n",
      "final loss=0.0006\n",
      "final loss=0.0003\n",
      "final loss=0.0005\n",
      "final loss=0.0008\n",
      "final loss=0.0004\n",
      "final loss=0.0006\n",
      "final loss=0.0006\n",
      "final loss=0.0004\n",
      "final loss=0.0006\n",
      "final loss=0.0004\n",
      "final loss=0.0005\n",
      "final loss=0.0006\n",
      "final loss=0.0006\n",
      "final loss=0.0004\n",
      "final loss=0.0007\n",
      "final loss=0.0006\n",
      "final loss=0.0007\n",
      "final loss=0.0005\n",
      "final loss=0.0006\n",
      "final loss=0.0002\n",
      "final loss=0.0005\n",
      "final loss=0.0004\n",
      "final loss=0.0007\n",
      "final loss=0.0006\n",
      "final loss=0.0004\n",
      "final loss=0.0005\n",
      "final loss=0.0008\n",
      "final loss=0.0005\n",
      "final loss=0.0006\n",
      "final loss=0.0004\n",
      "final loss=0.0006\n",
      "final loss=0.0007\n",
      "final loss=0.0006\n",
      "final loss=0.0004\n",
      "final loss=0.0005\n",
      "final loss=0.0005\n",
      "final loss=0.0002\n",
      "final loss=0.0005\n",
      "final loss=0.0005\n",
      "final loss=0.0004\n",
      "final loss=0.0006\n",
      "final loss=0.0005\n",
      "final loss=0.0004\n",
      "final loss=0.0008\n",
      "final loss=0.0005\n",
      "final loss=0.0003\n",
      "final loss=0.0005\n",
      "final loss=0.0005\n",
      "final loss=0.0005\n",
      "final loss=0.0003\n",
      "final loss=0.0005\n",
      "final loss=0.0005\n",
      "final loss=0.0002\n",
      "final loss=0.0006\n",
      "final loss=0.0006\n",
      "final loss=0.0006\n",
      "final loss=0.0005\n",
      "final loss=0.0007\n",
      "epoch [1000]/1000, loss=0.0003\n",
      "final loss=0.0003\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for words,labels in train_loader:\n",
    "        words = words.to(device)\n",
    "        labels = labels.to(dtype=torch.long).to(device)\n",
    "\n",
    "        output = model(words)\n",
    "        loss = criterion(output,labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'epoch [{epoch+1}]/{num_epochs}, loss={loss.item():.4f}')\n",
    "    print(f'final loss={loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"input_size\": input_size,\n",
    "    \"hidden_size\": hidden_size,\n",
    "    \"output_size\": output_size,\n",
    "    \"all_words\": all_words,\n",
    "    \"tags\": tags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed! File has been saved to TrainData.pth\n"
     ]
    }
   ],
   "source": [
    "file = \"TrainData.pth\"\n",
    "torch.save(data,file)\n",
    "print(f\"Training completed! File has been saved to {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = data[\"input_size\"]\n",
    "hidden_size = data[\"hidden_size\"]\n",
    "output_size = data[\"output_size\"]\n",
    "all_words = data[\"all_words\"]\n",
    "tags = data[\"tags\"]\n",
    "model_state = data[\"model_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (l1): Linear(in_features=17, out_features=8, bias=True)\n",
       "  (l2): Linear(in_features=8, out_features=8, bias=True)\n",
       "  (l3): Linear(in_features=8, out_features=3, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNet(input_size,hidden_size,output_size).to(device)\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"are you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = tokenize(sentence)\n",
    "X = BoW(sentence,all_words)\n",
    "X = np.array(X)\n",
    "X = X.reshape(1,X.shape[0])\n",
    "X = torch.from_numpy(X).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,predicted = torch.max(output,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = tags[predicted.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.softmax(output,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998018145561218"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = probs[0][predicted.item()]\n",
    "prob.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perfect\n"
     ]
    }
   ],
   "source": [
    "if prob.item() > 0.75:\n",
    "    for intent in intents['intents']:\n",
    "        if tag == intent['tag']:\n",
    "            reply = random.choice(intent['responses'])\n",
    "    print(reply)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOTffPFeZTicuTa23po81GM",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
